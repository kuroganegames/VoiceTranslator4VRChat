# coding: utf-8
"""
Voice Translator for VRChat (refactored)
"""

import os
from abc import ABC, abstractmethod
from io import BytesIO
from typing import List, Tuple, Optional, Dict, Any

import numpy as np
import soundfile as sf
import speech_recognition as sr
import torch
from pythonosc import udp_client
from transformers import (
    WhisperProcessor,
    WhisperForConditionalGeneration,
    AutoModelForSeq2SeqLM,
    AutoTokenizer,
)

# --------------------------------------------------
# â˜… è¨­å®šç”¨å®šæ•°  â˜…
# --------------------------------------------------
MIC_DEVICE_INDEX         = 2
MIC_SAMPLE_RATE          = 16_000

VRC_IP                   = "192.168.50.118"           # VRChat OSC ã‚µãƒ¼ãƒã® IP
VRC_PORT                 = 9000                      # VRChat OSC ã‚µãƒ¼ãƒã®ãƒãƒ¼ãƒˆ
CHATBOX_INPUT_ADDRESS    = "/chatbox/input"          # OSC ã‚¢ãƒ‰ãƒ¬ã‚¹

MODEL_ID_WHISPER         = "kotoba-tech/kotoba-whisper-v2.0"
MODEL_ID_TRANSLATION     = "facebook/nllb-200-distilled-600M"

CACHE_PATH               = r"G:\cache"               # ğŸ¤— Transformers ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥å…ˆ

REMOVE_WORDS             = ["ã”ã‚ã‚“"]                # ç„¡éŸ³èª¤èªè­˜ãƒ¯ãƒ¼ãƒ‰ã®é™¤å¤–
TRANSLATION_MAX_LENGTH   = 30                        # ç¿»è¨³æ–‡ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·
LOG_HISTORY_SIZE         = 3                         # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã™ã‚‹å±¥æ­´æ•°
DEVICE                   = "cuda" if torch.cuda.is_available() else "cpu"

# OpenAI APIè¨­å®šï¼ˆOpenAIç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ä½¿ç”¨æ™‚ï¼‰
OPENAI_API_KEY           = os.getenv("OPENAI_API_KEY", "")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
OPENAI_MODEL             = "gpt-3.5-turbo"                   # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
OPENAI_API_BASE          = None                              # ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆNone = ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

# ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã®é¸æŠ: "nllb" or "openai"
TRANSLATION_ENGINE       = "nllb"

# --------------------------------------------------
# ä»¥é™ã¯ã‚³ãƒ¼ãƒ‰æœ¬ä½“
# --------------------------------------------------


def clear_console() -> None:
    os.system("cls" if os.name == "nt" else "clear")


def print_banner(
    mode: str,
    history: List[str],
    translator_info: Optional[Dict[str, Any]] = None,
) -> None:
    """
    ç”»é¢ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒãƒŠãƒ¼ã¨å±¥æ­´ã‚’æç”»
    """
    if translator_info is None:
        translator_info = {}
    clear_console()
    history_lines = "\n".join(
        f"log{idx}:\t{line}"
        for idx, line in zip(
            range(LOG_HISTORY_SIZE, 0, -1), reversed(history[-LOG_HISTORY_SIZE :])
        )
    )
    print(
        f"""----------
Voice Translator for VRChat
----------
[MIC]
\tSELECTED INDEX:\t{MIC_DEVICE_INDEX}
\tSAMPLING_RATE:\t{MIC_SAMPLE_RATE}
[VRCHAT OCS CONNECTION]
\tIP:\t{VRC_IP}
\tPORT:\t{VRC_PORT}
[ML MODEL]
\tVOICE RECOGNITION MODEL:\t{MODEL_ID_WHISPER}
\tTRANSLATION ENGINE:\t{translator_info.get('name', 'Unknown')}
\tTRANSLATION MODEL:\t{translator_info.get('model', 'Unknown')}
\tDIR_MODEL_SAVE:\t{CACHE_PATH}
[REMOVE WORDS]
\t:\t{", ".join(REMOVE_WORDS)}
----------
MODE: {mode}
---
[HISTORY]
{history_lines}
----------""",
        flush=True,
    )


def send_to_vrchat_chatbox(message: str) -> None:
    """
    VRChat ChatBox ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
    """
    client = udp_client.SimpleUDPClient(VRC_IP, VRC_PORT)
    client.send_message(CHATBOX_INPUT_ADDRESS, [message, True])


class TranslatorEngine(ABC):
    """ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def initialize(self, **kwargs) -> None:
        """ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–"""
        pass
    
    @abstractmethod
    def translate(self, text: str, source_lang: str = "ja", target_lang: str = "en") -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³"""
        pass
    
    @abstractmethod
    def get_engine_info(self) -> Dict[str, Any]:
        """ã‚¨ãƒ³ã‚¸ãƒ³æƒ…å ±ã‚’å–å¾—"""
        pass


class NLLBTranslator(TranslatorEngine):
    """Facebook NLLBç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def initialize(self, **kwargs) -> None:
        self.tokenizer = AutoTokenizer.from_pretrained(
            MODEL_ID_TRANSLATION,
            token=True,
            src_lang="jpn_Jpan",
            cache_dir=CACHE_PATH,
        )
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            MODEL_ID_TRANSLATION,
            token=True,
            cache_dir=CACHE_PATH,
        )
    
    def translate(self, text: str, source_lang: str = "ja", target_lang: str = "en") -> str:
        inputs = self.tokenizer(text, return_tensors="pt")
        translated_tokens = self.model.generate(
            **inputs,
            forced_bos_token_id=self.tokenizer.convert_tokens_to_ids("eng_Latn"),
            max_length=TRANSLATION_MAX_LENGTH,
        )
        return self.tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
    
    def get_engine_info(self) -> Dict[str, Any]:
        return {
            "name": "NLLB",
            "model": MODEL_ID_TRANSLATION,
            "type": "local"
        }


class OpenAITranslator(TranslatorEngine):
    """OpenAI APIäº’æ›ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def initialize(self, **kwargs) -> None:
        try:
            import openai
            self.openai = openai
            
            # APIè¨­å®š
            if OPENAI_API_KEY:
                self.client = openai.OpenAI(
                    api_key=OPENAI_API_KEY,
                    base_url=OPENAI_API_BASE
                )
            else:
                raise ValueError("OPENAI_API_KEY is not set")
                
            self.model = kwargs.get("model", OPENAI_MODEL)
        except ImportError:
            raise ImportError("openai package is required. Install with: pip install openai")
    
    def translate(self, text: str, source_lang: str = "ja", target_lang: str = "en") -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"Translate the following {source_lang} text to {target_lang}. Provide only the translation without any explanation."},
                    {"role": "user", "content": text}
                ],
                temperature=0.3,
                max_tokens=TRANSLATION_MAX_LENGTH * 4  # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"[ERROR] OpenAI API error: {e}")
            return "[Translation Error]"
    
    def get_engine_info(self) -> Dict[str, Any]:
        return {
            "name": "OpenAI",
            "model": self.model,
            "type": "api",
            "base_url": OPENAI_API_BASE or "default"
        }


class VoiceTranslator:
    """éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆâ†’ç¿»è¨³â†’VRChat é€ä¿¡ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†"""

    def __init__(self, translation_engine: Optional[str] = None) -> None:
        self.recognizer = sr.Recognizer()
        self.processor = WhisperProcessor.from_pretrained(
            MODEL_ID_WHISPER, cache_dir=CACHE_PATH
        )
        self.model_whisper = WhisperForConditionalGeneration.from_pretrained(
            MODEL_ID_WHISPER, cache_dir=CACHE_PATH
        ).to(DEVICE)

        # ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã®é¸æŠã¨åˆæœŸåŒ–
        engine_type = translation_engine or TRANSLATION_ENGINE
        self.translator = self._create_translator(engine_type)
        self.translator.initialize()
        
        self.history: List[str] = []
    
    def _create_translator(self, engine_type: str) -> TranslatorEngine:
        """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã®ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ"""
        if engine_type.lower() == "nllb":
            return NLLBTranslator()
        elif engine_type.lower() == "openai":
            return OpenAITranslator()
        else:
            raise ValueError(f"Unknown translation engine: {engine_type}")

    # ---------- éŸ³å£°èªè­˜ â†’ æ—¥æœ¬èªæ–‡å­—åˆ— ---------- #
    def recognize_speech(self, wav_bytes: bytes) -> str:
        wav_stream = BytesIO(wav_bytes)
        audio_array, sampling_rate = sf.read(wav_stream)

        input_features = self.processor(
            audio_array, sampling_rate=sampling_rate, return_tensors="pt"
        ).input_features.to(DEVICE)

        generated_ids = self.model_whisper.generate(input_features)
        return self.processor.batch_decode(
            generated_ids, skip_special_tokens=True
        )[0]

    # ---------- æ—¥æœ¬èª â†’ è‹±èªç¿»è¨³ ---------- #
    def translate_to_en(self, text: str) -> str:
        return self.translator.translate(text, source_lang="ja", target_lang="en")

    # ---------- ç¿»è¨³ï¼‹ãƒ•ã‚£ãƒ«ã‚¿ ---------- #
    def filter_and_translate(self, jp_text: str) -> Tuple[str, bool]:
        if jp_text in REMOVE_WORDS:
            return "", False

        en_text = self.translate_to_en(jp_text)
        return f"{jp_text}\n{en_text}", True

    # ---------- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ---------- #
    def run(self) -> None:
        mode = "èµ·å‹•ä¸­..."
        translator_info = self.translator.get_engine_info()
        print_banner(mode, self.history, translator_info)

        try:
            while True:
                mode = "ãªã«ã‹è©±ã—ã¦ãã ã•ã„"
                print_banner(mode, self.history, translator_info)

                # éŒ²éŸ³
                with sr.Microphone(
                    device_index=MIC_DEVICE_INDEX, sample_rate=MIC_SAMPLE_RATE
                ) as source:
                    audio_data = self.recognizer.listen(source)

                # éŸ³å£°èªè­˜
                mode = "éŸ³å£°èªè­˜ä¸­..."
                print_banner(mode, self.history, translator_info)
                jp_text = self.recognize_speech(audio_data.get_wav_data())

                # ç¿»è¨³
                mode = "ç¿»è¨³ä¸­..."
                print_banner(mode, self.history, translator_info)
                text_to_send, should_send = self.filter_and_translate(jp_text)

                # é€ä¿¡ & ãƒ­ã‚°
                if should_send:
                    send_to_vrchat_chatbox(text_to_send)
                    self.history.append(text_to_send.replace("\n", "\t"))

        except KeyboardInterrupt:
            print("\n[INFO] KeyboardInterrupt â€” exiting gracefully.")


def main() -> None:
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚„config ã‹ã‚‰ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠå¯èƒ½
    # ä¾‹: translator = VoiceTranslator("openai")  # OpenAI APIã‚’ä½¿ç”¨
    translator = VoiceTranslator()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
    translator.run()


if __name__ == "__main__":
    main()